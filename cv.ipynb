{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system('pip install -r requirements.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение и запись изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Чтение изображения с помощью OpenCV\n",
    "image_cv2 = cv2.imread('path_to_image.jpg')  # Чтение в формате BGR\n",
    "image_cv2_rgb = cv2.cvtColor(image_cv2, cv2.COLOR_BGR2RGB)  # Конвертация в RGB\n",
    "\n",
    "# Чтение изображения с помощью PIL\n",
    "image_pil = Image.open('path_to_image.jpg')  # Чтение в формате RGB\n",
    "\n",
    "# Отображение изображения\n",
    "plt.imshow(image_cv2_rgb)  # Используем RGB для корректного отображения\n",
    "plt.axis('off')  # Скрываем оси\n",
    "plt.show()\n",
    "\n",
    "# Запись изображения с помощью OpenCV\n",
    "cv2.imwrite('output_image.jpg', image_cv2)\n",
    "\n",
    "# Запись изображения с помощью PIL\n",
    "image_pil.save('output_image_pil.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ параметров изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Путь к директории с изображениями\n",
    "image_dir = 'path_to_images'\n",
    "\n",
    "image_info = []\n",
    "\n",
    "for filename in tqdm(os.listdir(image_dir)):\n",
    "    if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        height, width, channels = image.shape\n",
    "        image_info.append({\n",
    "            'filename': filename,\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'channels': channels\n",
    "        })\n",
    "\n",
    "df_images = pd.DataFrame(image_info)\n",
    "\n",
    "print(df_images.describe())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_images['width'], df_images['height'], alpha=0.5)\n",
    "plt.title('Распределение размеров изображений')\n",
    "plt.xlabel('Ширина')\n",
    "plt.ylabel('Высота')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заготовка для YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 person, 2 apples, 1 orange, 1 dining table, 262.1ms\n",
      "Speed: 13.8ms preprocess, 262.1ms inference, 11.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Classes: tensor([49.,  0., 60., 47., 47.])\n",
      "Confidences: tensor([0.4157, 0.3148, 0.3132, 0.2729, 0.2664])\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Загрузка предобученной модели YOLOv8\n",
    "model = YOLO('yolov8n.pt')  # 'yolov8n.pt' - нано-модель\n",
    "\n",
    "# Чтение изображения\n",
    "image = cv2.imread('image.png')\n",
    "\n",
    "# Детекция объектов\n",
    "results = model(image)\n",
    "\n",
    "# Визуализация результатов\n",
    "for result in results:\n",
    "    result.show()  \n",
    "    result.save('output_image_yolo.jpg')  # Сохраняет результат\n",
    "\n",
    "# Получение информации о детекции\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Координаты bounding boxes\n",
    "    classes = boxes.cls  # Классы объектов\n",
    "    confidences = boxes.conf  # Уверенность модели\n",
    "    print(\"Classes:\", classes)\n",
    "    print(\"Confidences:\", confidences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
